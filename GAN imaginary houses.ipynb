{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.utils import save_image\n",
    "import torchvision.transforms as tt\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from adabelief_pytorch import AdaBelief\n",
    "from torch.nn import Parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "image_size = 512\n",
    "latent_size = image_size*2\n",
    "batch_size = 16\n",
    "lr = 0.0002\n",
    "current_epoch = 0\n",
    "stats = (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)\n",
    "\n",
    "nc = 3 \n",
    "ngf = 32 \n",
    "ndf = 32\n",
    "policy = 'color,translation,cutout'\n",
    "\n",
    "datadir = 'fantasy_houses_dataset'\n",
    "progressdir = 'saved_progress'\n",
    "os.makedirs(progressdir, exist_ok=True)\n",
    "\n",
    "device = torch.device('cuda:0' if (torch.cuda.is_available()) else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectral norm and DiffAugment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "# From: https://github.com/christiancosgrove/pytorch-spectral-normalization-gan\n",
    "def l2normalize(v, eps=1e-12):\n",
    "    return v / (v.norm() + eps)\n",
    "\n",
    "class SpectralNorm(nn.Module):\n",
    "    def __init__(self, module, name='weight', power_iterations=1):\n",
    "        super(SpectralNorm, self).__init__()\n",
    "        self.module = module\n",
    "        self.name = name\n",
    "        self.power_iterations = power_iterations\n",
    "        if not self._made_params():\n",
    "            self._make_params()\n",
    "\n",
    "    def _update_u_v(self):\n",
    "        u = getattr(self.module, self.name + \"_u\")\n",
    "        v = getattr(self.module, self.name + \"_v\")\n",
    "        w = getattr(self.module, self.name + \"_bar\")\n",
    "\n",
    "        height = w.data.shape[0]\n",
    "        for _ in range(self.power_iterations):\n",
    "            v.data = l2normalize(torch.mv(torch.t(w.view(height,-1).data), u.data))\n",
    "            u.data = l2normalize(torch.mv(w.view(height,-1).data, v.data))\n",
    "\n",
    "        # sigma = torch.dot(u.data, torch.mv(w.view(height,-1).data, v.data))\n",
    "        sigma = u.dot(w.view(height, -1).mv(v))\n",
    "        setattr(self.module, self.name, w / sigma.expand_as(w))\n",
    "\n",
    "    def _made_params(self):\n",
    "        try:\n",
    "            u = getattr(self.module, self.name + \"_u\")\n",
    "            v = getattr(self.module, self.name + \"_v\")\n",
    "            w = getattr(self.module, self.name + \"_bar\")\n",
    "            return True\n",
    "        except AttributeError:\n",
    "            return False\n",
    "\n",
    "\n",
    "    def _make_params(self):\n",
    "        w = getattr(self.module, self.name)\n",
    "\n",
    "        height = w.data.shape[0]\n",
    "        width = w.view(height, -1).data.shape[1]\n",
    "\n",
    "        u = Parameter(w.data.new(height).normal_(0, 1), requires_grad=False)\n",
    "        v = Parameter(w.data.new(width).normal_(0, 1), requires_grad=False)\n",
    "        u.data = l2normalize(u.data)\n",
    "        v.data = l2normalize(v.data)\n",
    "        w_bar = Parameter(w.data)\n",
    "\n",
    "        del self.module._parameters[self.name]\n",
    "\n",
    "        self.module.register_parameter(self.name + \"_u\", u)\n",
    "        self.module.register_parameter(self.name + \"_v\", v)\n",
    "        self.module.register_parameter(self.name + \"_bar\", w_bar)\n",
    "\n",
    "\n",
    "    def forward(self, *args):\n",
    "        self._update_u_v()\n",
    "        return self.module.forward(*args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "# From https://github.com/mit-han-lab/data-efficient-gans\n",
    "def DiffAugment(x, policy='', channels_first=True):\n",
    "    if policy:\n",
    "        if not channels_first:\n",
    "            x = x.permute(0, 3, 1, 2)\n",
    "        for p in policy.split(','):\n",
    "            for f in AUGMENT_FNS[p]:\n",
    "                x = f(x)\n",
    "        if not channels_first:\n",
    "            x = x.permute(0, 2, 3, 1)\n",
    "        x = x.contiguous()\n",
    "    return x\n",
    "\n",
    "\n",
    "def rand_brightness(x):\n",
    "    x = x + (torch.rand(x.size(0), 1, 1, 1, dtype=x.dtype, device=x.device) - 0.5)\n",
    "    return x\n",
    "\n",
    "\n",
    "def rand_saturation(x):\n",
    "    x_mean = x.mean(dim=1, keepdim=True)\n",
    "    x = (x - x_mean) * (torch.rand(x.size(0), 1, 1, 1, dtype=x.dtype, device=x.device) * 2) + x_mean\n",
    "    return x\n",
    "\n",
    "\n",
    "def rand_contrast(x):\n",
    "    x_mean = x.mean(dim=[1, 2, 3], keepdim=True)\n",
    "    x = (x - x_mean) * (torch.rand(x.size(0), 1, 1, 1, dtype=x.dtype, device=x.device) + 0.5) + x_mean\n",
    "    return x\n",
    "\n",
    "\n",
    "def rand_translation(x, ratio=0.125):\n",
    "    shift_x, shift_y = int(x.size(2) * ratio + 0.5), int(x.size(3) * ratio + 0.5)\n",
    "    translation_x = torch.randint(-shift_x, shift_x + 1, size=[x.size(0), 1, 1], device=x.device)\n",
    "    translation_y = torch.randint(-shift_y, shift_y + 1, size=[x.size(0), 1, 1], device=x.device)\n",
    "    grid_batch, grid_x, grid_y = torch.meshgrid(\n",
    "        torch.arange(x.size(0), dtype=torch.long, device=x.device),\n",
    "        torch.arange(x.size(2), dtype=torch.long, device=x.device),\n",
    "        torch.arange(x.size(3), dtype=torch.long, device=x.device),\n",
    "    )\n",
    "    grid_x = torch.clamp(grid_x + translation_x + 1, 0, x.size(2) + 1)\n",
    "    grid_y = torch.clamp(grid_y + translation_y + 1, 0, x.size(3) + 1)\n",
    "    x_pad = F.pad(x, [1, 1, 1, 1, 0, 0, 0, 0])\n",
    "    x = x_pad.permute(0, 2, 3, 1).contiguous()[grid_batch, grid_x, grid_y].permute(0, 3, 1, 2)\n",
    "    return x\n",
    "\n",
    "\n",
    "def rand_cutout(x, ratio=0.5):\n",
    "    cutout_size = int(x.size(2) * ratio + 0.5), int(x.size(3) * ratio + 0.5)\n",
    "    offset_x = torch.randint(0, x.size(2) + (1 - cutout_size[0] % 2), size=[x.size(0), 1, 1], device=x.device)\n",
    "    offset_y = torch.randint(0, x.size(3) + (1 - cutout_size[1] % 2), size=[x.size(0), 1, 1], device=x.device)\n",
    "    grid_batch, grid_x, grid_y = torch.meshgrid(\n",
    "        torch.arange(x.size(0), dtype=torch.long, device=x.device),\n",
    "        torch.arange(cutout_size[0], dtype=torch.long, device=x.device),\n",
    "        torch.arange(cutout_size[1], dtype=torch.long, device=x.device),\n",
    "    )\n",
    "    grid_x = torch.clamp(grid_x + offset_x - cutout_size[0] // 2, min=0, max=x.size(2) - 1)\n",
    "    grid_y = torch.clamp(grid_y + offset_y - cutout_size[1] // 2, min=0, max=x.size(3) - 1)\n",
    "    mask = torch.ones(x.size(0), x.size(2), x.size(3), dtype=x.dtype, device=x.device)\n",
    "    mask[grid_batch, grid_x, grid_y] = 0\n",
    "    x = x * mask.unsqueeze(1)\n",
    "    return x\n",
    "\n",
    "\n",
    "AUGMENT_FNS = {\n",
    "    'color': [rand_brightness, rand_saturation, rand_contrast],\n",
    "    'translation': [rand_translation],\n",
    "    'cutout': [rand_cutout],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ImageFolder(datadir, transform=tt.Compose([\n",
    "    tt.Resize(image_size),\n",
    "    tt.CenterCrop(image_size),\n",
    "    #tt.transforms.ColorJitter(brightness=0.25, contrast=0.25, saturation=0.25, hue=(-0.1,0.1)),\n",
    "    tt.RandomHorizontalFlip(),\n",
    "    tt.ToTensor(),\n",
    "    tt.Normalize(*stats)]))\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size, shuffle=True, num_workers=3, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View a batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_batch = next(iter(train_dl))\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.axis('off')\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:16], nrow=4, padding=2, normalize=True).cpu(),(1,2,0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator and discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = nn.Sequential(\n",
    "    nn.ConvTranspose2d(latent_size, ngf*64, kernel_size=4, stride=1, padding=0, bias=False),\n",
    "    nn.BatchNorm2d(ngf*64),\n",
    "    nn.ReLU(True),\n",
    "    nn.ConvTranspose2d(ngf*64, ngf*32, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "    nn.BatchNorm2d(ngf*32),\n",
    "    nn.ReLU(True),\n",
    "    nn.ConvTranspose2d(ngf*32, ngf*16, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "    nn.BatchNorm2d(ngf*16),\n",
    "    nn.ReLU(True),\n",
    "    nn.ConvTranspose2d(ngf*16, ngf*8, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "    nn.BatchNorm2d(ngf*8),\n",
    "    nn.ReLU(True),\n",
    "    nn.ConvTranspose2d(ngf*8, ngf*4, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "    nn.BatchNorm2d(ngf*4),\n",
    "    nn.ReLU(True),\n",
    "    nn.ConvTranspose2d(ngf*4, ngf*2, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "    nn.BatchNorm2d(ngf*2),\n",
    "    nn.ReLU(True),   \n",
    "    nn.ConvTranspose2d(ngf*2, ngf, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "    nn.BatchNorm2d(ngf),\n",
    "    nn.ReLU(True),  \n",
    "    nn.ConvTranspose2d(ngf, nc, kernel_size=4, stride=2, padding=1),\n",
    "    nn.Tanh()\n",
    ")\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = SpectralNorm(nn.Conv2d(nc, ndf, 4, stride=2, padding=1))\n",
    "        self.conv2 = SpectralNorm(nn.Conv2d(ndf, ndf*2, kernel_size=4, stride=2, padding=1))\n",
    "        self.conv3 = SpectralNorm(nn.Conv2d(ndf*2, ndf*4, kernel_size=4, stride=2, padding=1))\n",
    "        self.conv4 = SpectralNorm(nn.Conv2d(ndf*4, ndf*8, kernel_size=4, stride=2, padding=1))\n",
    "        self.conv5 = SpectralNorm(nn.Conv2d(ndf*8, ndf*16, kernel_size=4, stride=2, padding=1))\n",
    "        self.conv6 = SpectralNorm(nn.Conv2d(ndf*16, ndf*32, kernel_size=4, stride=2, padding=1))\n",
    "        self.conv66 = SpectralNorm(nn.Conv2d(ndf*32, ndf*64, kernel_size=4, stride=2, padding=1))\n",
    "        self.conv7 = nn.Conv2d(ndf*64, 1, kernel_size=4, stride=1, padding=0)\n",
    "        self.leakyrelu = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.leakyrelu(self.conv1(x))\n",
    "        x = self.leakyrelu(self.conv2(x))\n",
    "        x = self.leakyrelu(self.conv3(x))\n",
    "        x = self.leakyrelu(self.conv4(x))\n",
    "        x = self.leakyrelu(self.conv5(x))\n",
    "        x = self.leakyrelu(self.conv6(x))\n",
    "        x = self.leakyrelu(self.conv66(x))\n",
    "        x = self.flatten(self.conv7(x))\n",
    "        x = self.sigmoid(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving images, progress, losses, and scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "def denorm(img_tensors):\n",
    "    return img_tensors*stats[1][0]+stats[0][0]\n",
    "\n",
    "def save_progress_image(idx):\n",
    "    generator_images = (generator(latent.detach())).to('cpu')\n",
    "    name = 'image-{0:0=5d}.png'.format(idx+current_epoch)\n",
    "    save_image(denorm(generator_images),os.path.join(progressdir, name), nrow=4)\n",
    "      \n",
    "def save_histories(his):\n",
    "    if os.path.exists(progressdir+'/histories.pt'):\n",
    "        losses_g, losses_d, fake_pr, real_pr = torch.load(progressdir+'/histories.pt')\n",
    "    else:\n",
    "        losses_g, losses_d, fake_pr, real_pr = [],[],[],[]\n",
    "        \n",
    "    losses_g += his[0]\n",
    "    losses_d += his[1]\n",
    "    fake_pr += his[2]\n",
    "    real_pr += his[3]\n",
    "    histories = losses_g, losses_d, fake_pr, real_pr\n",
    "    torch.save(histories, './'+progressdir+'/histories.pt')\n",
    "\n",
    "def save_state():\n",
    "    torch.save(generator.state_dict(), progressdir+'/G'+str(epochs+current_epoch)+'.pth')\n",
    "    torch.save(discriminator.state_dict(), progressdir+'/D'+str(epochs+current_epoch)+'.pth')\n",
    "    \n",
    "def plot_losses():\n",
    "    losses_g, losses_d, _, _ = torch.load(progressdir+'/histories.pt')\n",
    "    plt.figure(figsize=(30,10))\n",
    "    plt.plot(losses_d, '-')\n",
    "    plt.plot(losses_g, '-')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(['Discriminator', 'Generator'])\n",
    "    plt.title('Losses')  \n",
    "      \n",
    "def plot_scores():\n",
    "    _, _, fake_pr, real_pr = torch.load(progressdir+'/histories.pt')\n",
    "    plt.figure(figsize=(30,10))\n",
    "    plt.plot(real_pr, '-')\n",
    "    plt.plot(fake_pr, '-')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('score')\n",
    "    plt.legend(['Real', 'Fake'])\n",
    "    plt.title('Scores')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a latent vector for saving progress images and save generator output prior to training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent = torch.randn(batch_size,latent_size, 1, 1)\n",
    "# torch.save(latent, 'saved_latent.pt')\n",
    "# latent = torch.load('saved_latent.pt')\n",
    "\n",
    "# save generator output prior to training:\n",
    "save_progress_image(0)\n",
    "\n",
    "# move latent to device:\n",
    "latent = latent.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator and discriminator training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator(optim_g, num_images):\n",
    "    # Generate images with generator:\n",
    "    latent = torch.randn(num_images, latent_size, 1, 1, device=device)\n",
    "    fake_images = generator(latent)\n",
    "    \n",
    "    # Give discriminator generator images:\n",
    "    preds = discriminator(DiffAugment(fake_images, policy=policy))\n",
    "    targets = torch.ones(num_images, 1, device=device)\n",
    "    loss = F.binary_cross_entropy(preds, targets)\n",
    "    \n",
    "    # Update weights:\n",
    "    loss.backward()\n",
    "    optim_g.step()  \n",
    "    return loss.item()\n",
    "\n",
    "def train_discriminator(real_images, optim_d, num_images):\n",
    "    # Give discriminator real images:\n",
    "    real_preds = discriminator(DiffAugment(real_images, policy=policy))\n",
    "    real_targets = (torch.ones(num_images, 1, device=device))#*(1-np.random.uniform(-0.1, 0.1)) #label smoothing (not used for imaginary houses model)\n",
    "    real_loss = F.binary_cross_entropy(real_preds, real_targets)\n",
    "    real_score = torch.mean(real_preds).item()\n",
    "    \n",
    "    # Generate images with generator:\n",
    "    latent = torch.randn(num_images, latent_size, 1, 1, device=device)\n",
    "    fake_images = generator(latent)  \n",
    "\n",
    "    # Give discriminator generator images:\n",
    "    fake_targets = torch.zeros(num_images, 1, device=device)\n",
    "    fake_preds = discriminator(DiffAugment(fake_images, policy=policy))\n",
    "    fake_loss = F.binary_cross_entropy(fake_preds, fake_targets)\n",
    "    fake_score = torch.mean(fake_preds).item()\n",
    "    \n",
    "    # Update weights:\n",
    "    loss = real_loss + fake_loss\n",
    "    loss.backward()\n",
    "    optim_d.step()\n",
    "    return loss.item(), real_score, fake_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = Discriminator().to(device)\n",
    "generator = generator.to(device)\n",
    "\n",
    "def fit(epochs):\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    losses_g, losses_d, real_scores, fake_scores = [],[],[],[]\n",
    "    \n",
    "    # Optimizers:\n",
    "    optim_d = AdaBelief(discriminator.parameters(), eps=1e-16, lr=lr, betas=(0.5, 0.999), \n",
    "                           weight_decay=0, \n",
    "                           weight_decouple=True, \n",
    "                           rectify=True,\n",
    "                           fixed_decay=False,\n",
    "                           amsgrad=False,\n",
    "                           print_change_log = False)\n",
    "    optim_g = AdaBelief(generator.parameters(), eps=1e-16, lr=lr, betas=(0.5, 0.999), \n",
    "                           weight_decay=0, \n",
    "                           weight_decouple=True, \n",
    "                           rectify=True,\n",
    "                           fixed_decay=False,\n",
    "                           amsgrad=False,\n",
    "                           print_change_log = False)\n",
    "\n",
    "    \n",
    "    # Training:\n",
    "    for e in range(epochs):\n",
    "        for image, _ in tqdm(train_dataloader):\n",
    "            image = DeviceDataLoader(image, device)\n",
    "            num_images = image.size(0)\n",
    "            optim_d.zero_grad()\n",
    "            loss_d, real_score, fake_score = train_discriminator(image.to(device), optim_d, num_images)\n",
    "            optim_g.zero_grad()\n",
    "            loss_g = train_generator(optim_g, num_images)\n",
    "            \n",
    "        # Record losses and scores:    \n",
    "        losses_g.append(loss_g)\n",
    "        losses_d.append(loss_d)\n",
    "        fake_scores.append(fake_score)\n",
    "        real_scores.append(real_score)\n",
    "        \n",
    "        # Print losses and scores for the last batch: \n",
    "        print(\"epoch: [{}/{}], loss_gen: {:.4f}, loss_disc: {:.4f}, fake_preds: {:.4f}, real_preds: {:.4f}\".format(\n",
    "            e+1, epochs, loss_g, loss_d, fake_score, real_score))\n",
    "    \n",
    "        # Save generated images every 5 epochs (or every epoch):\n",
    "#         if (e+1)%5 == 0:\n",
    "        save_progress_image(e+1)\n",
    "        \n",
    "    \n",
    "    return losses_g, losses_d, fake_scores, real_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save generator output prior to training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_progress_image()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model for 5 epochs and save losses, scores, and weights at the end:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "current_epoch = 0\n",
    "history = fit(epochs)\n",
    "save_histories(history)\n",
    "save_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot losses and scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses()\n",
    "plot_scores()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
